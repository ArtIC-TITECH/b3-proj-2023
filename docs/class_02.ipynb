{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前回のコードのまとめ\n",
    "本日の演習では、こちらの学習コードを使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ArtIC-TITECH/b3-proj-2023/blob/feature/class_02/docs/class_02.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch関連ライブラリ\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Please update the path to your own directory.\n",
    "# path=/path/to/your_own  # Uncomment this line\n",
    "path = '../../work/data/cifar10'\n",
    "\n",
    "## Define Augmentation\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "     ])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "n_samples = len(trainset)\n",
    "trainsize = int(n_samples * 0.8)\n",
    "\n",
    "trainsubset, validsubset = torch.utils.data.random_split(trainset, [trainsize, n_samples-trainsize])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainsubset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(validsubset, batch_size=batch_size, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(loader, model):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data[0].to('cuda:0'), data[1].to('cuda:0')\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    net.train()\n",
    "    return 100.0 * correct / total\n",
    "\n",
    "def accuracy_batch(outputs, labels):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total = labels.size(0)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.047, validation accuracy: 31.66, batch accuracy: 39.0625\n",
      "[1,   200] loss: 1.712, validation accuracy: 40.96, batch accuracy: 31.25\n",
      "[1,   300] loss: 1.604, validation accuracy: 43.37, batch accuracy: 44.53125\n",
      "[2,   100] loss: 1.530, validation accuracy: 44.24, batch accuracy: 45.3125\n",
      "[2,   200] loss: 1.513, validation accuracy: 46.55, batch accuracy: 51.5625\n",
      "[2,   300] loss: 1.473, validation accuracy: 47.36, batch accuracy: 46.09375\n",
      "[3,   100] loss: 1.430, validation accuracy: 47.51, batch accuracy: 50.0\n",
      "[3,   200] loss: 1.416, validation accuracy: 50.6, batch accuracy: 53.125\n",
      "[3,   300] loss: 1.451, validation accuracy: 48.52, batch accuracy: 55.46875\n",
      "[4,   100] loss: 1.396, validation accuracy: 50.19, batch accuracy: 43.75\n",
      "[4,   200] loss: 1.400, validation accuracy: 51.7, batch accuracy: 55.46875\n",
      "[4,   300] loss: 1.374, validation accuracy: 50.41, batch accuracy: 50.78125\n",
      "[5,   100] loss: 1.326, validation accuracy: 53.83, batch accuracy: 55.46875\n",
      "[5,   200] loss: 1.359, validation accuracy: 51.39, batch accuracy: 46.09375\n",
      "[5,   300] loss: 1.399, validation accuracy: 51.35, batch accuracy: 49.21875\n",
      "[6,   100] loss: 1.266, validation accuracy: 52.0, batch accuracy: 56.25\n",
      "[6,   200] loss: 1.321, validation accuracy: 51.51, batch accuracy: 59.375\n",
      "[6,   300] loss: 1.319, validation accuracy: 53.4, batch accuracy: 55.46875\n",
      "[7,   100] loss: 1.261, validation accuracy: 53.16, batch accuracy: 62.5\n",
      "[7,   200] loss: 1.295, validation accuracy: 48.83, batch accuracy: 49.21875\n",
      "[7,   300] loss: 1.354, validation accuracy: 53.79, batch accuracy: 57.8125\n",
      "[8,   100] loss: 1.228, validation accuracy: 52.75, batch accuracy: 53.90625\n",
      "[8,   200] loss: 1.304, validation accuracy: 51.81, batch accuracy: 59.375\n",
      "[8,   300] loss: 1.309, validation accuracy: 53.95, batch accuracy: 56.25\n",
      "[9,   100] loss: 1.238, validation accuracy: 52.07, batch accuracy: 60.9375\n",
      "[9,   200] loss: 1.302, validation accuracy: 51.55, batch accuracy: 50.78125\n",
      "[9,   300] loss: 1.308, validation accuracy: 47.16, batch accuracy: 56.25\n",
      "[10,   100] loss: 1.236, validation accuracy: 55.09, batch accuracy: 59.375\n",
      "[10,   200] loss: 1.295, validation accuracy: 50.26, batch accuracy: 58.59375\n",
      "[10,   300] loss: 1.351, validation accuracy: 53.18, batch accuracy: 63.28125\n",
      "[11,   100] loss: 1.243, validation accuracy: 49.54, batch accuracy: 50.0\n",
      "[11,   200] loss: 1.340, validation accuracy: 52.61, batch accuracy: 60.15625\n",
      "[11,   300] loss: 1.270, validation accuracy: 52.35, batch accuracy: 53.90625\n",
      "[12,   100] loss: 1.292, validation accuracy: 52.14, batch accuracy: 57.03125\n",
      "[12,   200] loss: 1.271, validation accuracy: 52.42, batch accuracy: 58.59375\n",
      "[12,   300] loss: 1.296, validation accuracy: 51.44, batch accuracy: 58.59375\n",
      "[13,   100] loss: 1.251, validation accuracy: 52.86, batch accuracy: 56.25\n",
      "[13,   200] loss: 1.295, validation accuracy: 51.37, batch accuracy: 57.8125\n",
      "[13,   300] loss: 1.351, validation accuracy: 50.43, batch accuracy: 57.8125\n",
      "[14,   100] loss: 1.251, validation accuracy: 52.08, batch accuracy: 57.8125\n",
      "[14,   200] loss: 1.314, validation accuracy: 51.74, batch accuracy: 55.46875\n",
      "[14,   300] loss: 1.326, validation accuracy: 50.91, batch accuracy: 52.34375\n",
      "[15,   100] loss: 1.291, validation accuracy: 50.4, batch accuracy: 59.375\n",
      "[15,   200] loss: 1.308, validation accuracy: 53.31, batch accuracy: 58.59375\n",
      "[15,   300] loss: 1.286, validation accuracy: 50.68, batch accuracy: 46.09375\n",
      "[16,   100] loss: 1.304, validation accuracy: 51.59, batch accuracy: 54.6875\n",
      "[16,   200] loss: 1.286, validation accuracy: 51.78, batch accuracy: 57.03125\n",
      "[16,   300] loss: 1.308, validation accuracy: 53.11, batch accuracy: 53.125\n",
      "[17,   100] loss: 1.260, validation accuracy: 50.67, batch accuracy: 60.9375\n",
      "[17,   200] loss: 1.309, validation accuracy: 52.27, batch accuracy: 56.25\n",
      "[17,   300] loss: 1.299, validation accuracy: 52.91, batch accuracy: 62.5\n",
      "[18,   100] loss: 1.247, validation accuracy: 50.01, batch accuracy: 60.15625\n",
      "[18,   200] loss: 1.353, validation accuracy: 50.03, batch accuracy: 54.6875\n",
      "[18,   300] loss: 1.327, validation accuracy: 51.48, batch accuracy: 56.25\n",
      "[19,   100] loss: 1.274, validation accuracy: 50.08, batch accuracy: 57.03125\n",
      "[19,   200] loss: 1.333, validation accuracy: 51.79, batch accuracy: 48.4375\n",
      "[19,   300] loss: 1.312, validation accuracy: 51.51, batch accuracy: 55.46875\n",
      "[20,   100] loss: 1.256, validation accuracy: 49.06, batch accuracy: 51.5625\n",
      "[20,   200] loss: 1.309, validation accuracy: 52.63, batch accuracy: 62.5\n",
      "[20,   300] loss: 1.371, validation accuracy: 51.84, batch accuracy: 54.6875\n",
      "[21,   100] loss: 1.307, validation accuracy: 51.95, batch accuracy: 62.5\n",
      "[21,   200] loss: 1.327, validation accuracy: 50.0, batch accuracy: 56.25\n",
      "[21,   300] loss: 1.352, validation accuracy: 50.75, batch accuracy: 62.5\n",
      "[22,   100] loss: 1.286, validation accuracy: 50.11, batch accuracy: 50.0\n",
      "[22,   200] loss: 1.283, validation accuracy: 50.1, batch accuracy: 58.59375\n",
      "[22,   300] loss: 1.387, validation accuracy: 49.59, batch accuracy: 49.21875\n",
      "[23,   100] loss: 1.331, validation accuracy: 50.97, batch accuracy: 55.46875\n",
      "[23,   200] loss: 1.348, validation accuracy: 50.42, batch accuracy: 57.03125\n",
      "[23,   300] loss: 1.318, validation accuracy: 52.38, batch accuracy: 57.8125\n",
      "[24,   100] loss: 1.319, validation accuracy: 49.57, batch accuracy: 64.0625\n",
      "[24,   200] loss: 1.359, validation accuracy: 52.13, batch accuracy: 50.78125\n",
      "[24,   300] loss: 1.352, validation accuracy: 51.64, batch accuracy: 55.46875\n",
      "[25,   100] loss: 1.294, validation accuracy: 51.0, batch accuracy: 53.125\n",
      "[25,   200] loss: 1.345, validation accuracy: 43.11, batch accuracy: 54.6875\n",
      "[25,   300] loss: 1.442, validation accuracy: 48.32, batch accuracy: 57.8125\n",
      "[26,   100] loss: 1.333, validation accuracy: 51.25, batch accuracy: 49.21875\n",
      "[26,   200] loss: 1.379, validation accuracy: 49.56, batch accuracy: 54.6875\n",
      "[26,   300] loss: 1.343, validation accuracy: 51.96, batch accuracy: 54.6875\n",
      "[27,   100] loss: 1.417, validation accuracy: 50.34, batch accuracy: 53.125\n",
      "[27,   200] loss: 1.361, validation accuracy: 47.17, batch accuracy: 57.8125\n",
      "[27,   300] loss: 1.394, validation accuracy: 51.78, batch accuracy: 58.59375\n",
      "[28,   100] loss: 1.340, validation accuracy: 49.78, batch accuracy: 58.59375\n",
      "[28,   200] loss: 1.371, validation accuracy: 52.96, batch accuracy: 58.59375\n",
      "[28,   300] loss: 1.335, validation accuracy: 50.95, batch accuracy: 56.25\n",
      "[29,   100] loss: 1.318, validation accuracy: 50.22, batch accuracy: 65.625\n",
      "[29,   200] loss: 1.353, validation accuracy: 50.48, batch accuracy: 52.34375\n",
      "[29,   300] loss: 1.383, validation accuracy: 49.34, batch accuracy: 63.28125\n",
      "[30,   100] loss: 1.341, validation accuracy: 46.96, batch accuracy: 53.90625\n",
      "[30,   200] loss: 1.361, validation accuracy: 49.13, batch accuracy: 54.6875\n",
      "[30,   300] loss: 1.407, validation accuracy: 42.89, batch accuracy: 58.59375\n",
      "[31,   100] loss: 1.340, validation accuracy: 50.61, batch accuracy: 64.0625\n",
      "[31,   200] loss: 1.392, validation accuracy: 48.85, batch accuracy: 49.21875\n",
      "[31,   300] loss: 1.413, validation accuracy: 50.5, batch accuracy: 60.9375\n",
      "[32,   100] loss: 1.362, validation accuracy: 48.14, batch accuracy: 53.90625\n",
      "[32,   200] loss: 1.393, validation accuracy: 48.5, batch accuracy: 54.6875\n",
      "[32,   300] loss: 1.409, validation accuracy: 47.27, batch accuracy: 52.34375\n",
      "[33,   100] loss: 1.457, validation accuracy: 49.36, batch accuracy: 56.25\n",
      "[33,   200] loss: 1.489, validation accuracy: 46.87, batch accuracy: 48.4375\n",
      "[33,   300] loss: 1.465, validation accuracy: 47.61, batch accuracy: 53.125\n",
      "[34,   100] loss: 1.487, validation accuracy: 48.55, batch accuracy: 50.0\n",
      "[34,   200] loss: 1.545, validation accuracy: 43.8, batch accuracy: 45.3125\n",
      "[34,   300] loss: 1.646, validation accuracy: 42.27, batch accuracy: 56.25\n",
      "[35,   100] loss: 1.504, validation accuracy: 42.13, batch accuracy: 46.09375\n",
      "[35,   200] loss: 1.532, validation accuracy: 45.86, batch accuracy: 48.4375\n",
      "[35,   300] loss: 1.567, validation accuracy: 44.44, batch accuracy: 51.5625\n",
      "[36,   100] loss: 1.505, validation accuracy: 48.84, batch accuracy: 55.46875\n",
      "[36,   200] loss: 1.522, validation accuracy: 44.79, batch accuracy: 46.09375\n",
      "[36,   300] loss: 1.522, validation accuracy: 48.97, batch accuracy: 53.90625\n",
      "[37,   100] loss: 1.577, validation accuracy: 42.58, batch accuracy: 42.96875\n",
      "[37,   200] loss: 1.569, validation accuracy: 46.89, batch accuracy: 54.6875\n",
      "[37,   300] loss: 1.617, validation accuracy: 38.46, batch accuracy: 38.28125\n",
      "[38,   100] loss: 1.728, validation accuracy: 41.55, batch accuracy: 44.53125\n",
      "[38,   200] loss: 1.641, validation accuracy: 44.59, batch accuracy: 47.65625\n",
      "[38,   300] loss: 1.629, validation accuracy: 46.31, batch accuracy: 64.84375\n",
      "[39,   100] loss: 1.589, validation accuracy: 42.13, batch accuracy: 49.21875\n",
      "[39,   200] loss: 1.692, validation accuracy: 32.56, batch accuracy: 32.8125\n",
      "[39,   300] loss: 1.777, validation accuracy: 39.04, batch accuracy: 36.71875\n",
      "[40,   100] loss: 1.726, validation accuracy: 36.57, batch accuracy: 39.0625\n",
      "[40,   200] loss: 1.816, validation accuracy: 30.2, batch accuracy: 36.71875\n",
      "[40,   300] loss: 1.811, validation accuracy: 34.48, batch accuracy: 38.28125\n",
      "[41,   100] loss: 1.792, validation accuracy: 33.05, batch accuracy: 32.03125\n",
      "[41,   200] loss: 1.892, validation accuracy: 27.89, batch accuracy: 28.125\n",
      "[41,   300] loss: 1.847, validation accuracy: 35.88, batch accuracy: 39.0625\n",
      "[42,   100] loss: 1.793, validation accuracy: 34.9, batch accuracy: 44.53125\n",
      "[42,   200] loss: 1.820, validation accuracy: 29.73, batch accuracy: 31.25\n",
      "[42,   300] loss: 1.868, validation accuracy: 36.51, batch accuracy: 34.375\n",
      "[43,   100] loss: 1.801, validation accuracy: 30.61, batch accuracy: 37.5\n",
      "[43,   200] loss: 1.848, validation accuracy: 29.56, batch accuracy: 41.40625\n",
      "[43,   300] loss: 1.845, validation accuracy: 30.75, batch accuracy: 28.90625\n",
      "[44,   100] loss: 1.880, validation accuracy: 27.01, batch accuracy: 28.90625\n",
      "[44,   200] loss: 1.974, validation accuracy: 27.35, batch accuracy: 33.59375\n",
      "[44,   300] loss: 1.886, validation accuracy: 25.23, batch accuracy: 34.375\n",
      "[45,   100] loss: 1.871, validation accuracy: 26.03, batch accuracy: 28.125\n",
      "[45,   200] loss: 2.028, validation accuracy: 25.63, batch accuracy: 25.78125\n",
      "[45,   300] loss: 1.949, validation accuracy: 29.31, batch accuracy: 30.46875\n",
      "[46,   100] loss: 1.918, validation accuracy: 22.72, batch accuracy: 21.875\n",
      "[46,   200] loss: 1.900, validation accuracy: 31.44, batch accuracy: 28.90625\n",
      "[46,   300] loss: 1.968, validation accuracy: 20.57, batch accuracy: 20.3125\n",
      "[47,   100] loss: 1.974, validation accuracy: 27.37, batch accuracy: 25.78125\n",
      "[47,   200] loss: 2.084, validation accuracy: 19.49, batch accuracy: 23.4375\n",
      "[47,   300] loss: 2.066, validation accuracy: 16.9, batch accuracy: 14.84375\n",
      "[48,   100] loss: 2.329, validation accuracy: 10.52, batch accuracy: 13.28125\n",
      "[48,   200] loss: 2.299, validation accuracy: 10.04, batch accuracy: 7.8125\n",
      "[48,   300] loss: 2.304, validation accuracy: 9.77, batch accuracy: 7.8125\n",
      "[49,   100] loss: 2.305, validation accuracy: 9.87, batch accuracy: 4.6875\n",
      "[49,   200] loss: 2.304, validation accuracy: 9.95, batch accuracy: 10.15625\n",
      "[49,   300] loss: 2.304, validation accuracy: 10.58, batch accuracy: 11.71875\n",
      "[50,   100] loss: 2.304, validation accuracy: 9.89, batch accuracy: 14.0625\n",
      "[50,   200] loss: 2.304, validation accuracy: 9.77, batch accuracy: 10.9375\n",
      "[50,   300] loss: 2.305, validation accuracy: 9.57, batch accuracy: 7.8125\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to('cuda:0'), data[1].to('cuda:0')\n",
    "\n",
    "        # 1. forward\n",
    "        outputs = net(inputs)\n",
    "        # 2. compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 3. reset parameter gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            ## Calculate validation accuracy\n",
    "            val_acc = accuracy(valloader, net)\n",
    "\n",
    "            ## Calculate batch accuracy\n",
    "            batch_acc = accuracy_batch(outputs=outputs, labels=labels)\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}, validation accuracy: {val_acc}, batch accuracy: {batch_acc}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "accuracy(testloader, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前回の課題\n",
    "\n",
    "`Net`クラスを修正して以下で定義されるモデルを実装してください。\\\n",
    "Conv2dは全て`padding=0`、`stride=1`で、MaxPool2dは`stride=2`で実装してください。\\\n",
    "それぞれの層のカーネルサイズは、テーブルの`Kernel Shape`を元に決定してください。\\\n",
    "それぞれの層のチャネル数は、入力チャネル、出力チャネルを参考に実装してください。\\\n",
    "\n",
    "```\n",
    "===================================================================================================================\n",
    "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape\n",
    "===================================================================================================================\n",
    "Net                                      [4, 3, 32, 32]            [4, 10]                   --\n",
    "├─Conv2d: 1-1                            [4, 3, 32, 32]            [4, 6, 28, 28]            [5, 5]\n",
    "│    └─weight                                                                                [3, 6, 5, 5]\n",
    "│    └─bias                                                                                  [6]\n",
    "|-ReLU                                   [4, 6, 28, 28]            [4, 6, 28, 28]\n",
    "├─MaxPool2d: 1-2                         [4, 6, 28, 28]            [4, 6, 14, 14]            2\n",
    "├─Conv2d: 1-3                            [4, 6, 14, 14]            [4, 16, 10, 10]           [5, 5]\n",
    "│    └─weight                                                                                [6, 16, 5, 5]\n",
    "│    └─bias                                                                                  [16]\n",
    "|-ReLU                                   [4, 16, 10, 10]           [4, 16, 10, 10]\n",
    "├─MaxPool2d: 1-4                         [4, 16, 10, 10]           [4, 16, 5, 5]             2\n",
    "├─Linear: 1-5                            [4, 400]                  [4, 120]                  --\n",
    "│    └─weight                                                                                [400, 120]\n",
    "│    └─bias                                                                                  [120]\n",
    "|-ReLU                                   [4, 120]                  [4, 120]\n",
    "├─Linear: 1-6                            [4, 120]                  [4, 84]                   --\n",
    "│    └─weight                                                                                [120, 84]\n",
    "│    └─bias                                                                                  [84]\n",
    "|-ReLU                                   [4, 84]                   [4, 84]\n",
    "├─Linear: 1-7                            [4, 84]                   [4, 10]                   --\n",
    "│    └─weight                                                                                [84, 10]\n",
    "│    └─bias                                                                                  [10]\n",
    "===================================================================================================================\n",
    "```\n",
    "\n",
    "### 結果の確認\n",
    "\n",
    "はじめに自身で定義したモデルが一致しているか確認したいと思います。\\\n",
    "まずは、Netを定義しているセルに移動して先週自分で実装したモデルと入れ替えてください。\n",
    "\n",
    "今回は出力が一致しているか確認するための検証データを用意しているのでそちらと結果が一致するか確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 検証用のデータのダウンロード\n",
    "!curl -L -o model_out.pt https://github.com/ArtIC-TITECH/b3-proj-2023/raw/main/resources/model_out.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下のセルを実行して何もエラーが発生しなければモデルが正しく実装できていることになります。\\\n",
    "結果が一致しない場合はモデルが正しく定義できているかもう一度確認してみましょう。\\\n",
    "(乱数のシードを一致させることで入出力の再現をしているため、モデルを定義する際の順序が異なると結果が一致しない可能性があります。層を実行する順番と定義する順番が一致するように注意してください。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(100)\n",
    "\n",
    "input = torch.rand((1, 3, 32, 32))\n",
    "net = Net()\n",
    "output = net(input)\n",
    "\n",
    "valid = torch.load('./model_out.pt')\n",
    "\n",
    "assert torch.isclose(valid, output).all(), \"Validation is failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解答\n",
    "\n",
    "本日の演習ではこちらのモデルを使用するため、結果が一致しない場合は`Net`の定義をこちらのモデルに書き換えてください。\n",
    "\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboardを利用したモデルの可視化\n",
    "\n",
    "本日は`Tensorboard`というライブラリを使用した学習経過の視覚化を行います。\\\n",
    "学習過程を観察することでモデルの精度を上げるためのヒントを得られることがあります。\n",
    "\n",
    "まず、`Tensorboard`をGoogle Colabo上で利用可能にするには下記のコマンドを実行する必要があります。\n",
    "pytorchのライブラリをimportするセルの上に新しいセルを作成して、下記のコマンドをコピーした後に実行してください。\n",
    "\n",
    "### writerの定義\n",
    "\n",
    "tensorboardのSummaryWriterというクラスを用いてwriterを初期化します。\n",
    "下のセルにおいて、`path`を自身のGoogle Driveのパスに変更してください。\n",
    "\n",
    "```python\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "## Put your google drive path\n",
    "path = ''\n",
    "run_name = 'runs/cifar10_experiments1'\n",
    "run_dir = os.path.join(path, run_name)\n",
    "\n",
    "writer = SummaryWriter(run_dir)\n",
    "```\n",
    "\n",
    "別の実験を行う場合は`run_name`を`runs/cifar10_experimentsN`等に変更するようにしてください。\n",
    "実験を行いやすいようwriterを定義するセルの場所は適宜変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define writer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "## Put your google drive path\n",
    "path = ''\n",
    "run_name = 'runs/cifar10_experiments1'\n",
    "run_dir = os.path.join(path, run_name)\n",
    "\n",
    "writer = SummaryWriter(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboardを使ったモデル構造の出力\n",
    "\n",
    "`writer.add_xxx`という関数を呼び出すことでwriterにデータを記録することができます。\\\n",
    "(xxxは記録したいデータによって変わります。)\n",
    "\n",
    "まず初めに、モデル構造をtensorboardに記録してみましょう。\n",
    "次のセルを実行してみてください。\n",
    "\n",
    "`add_graph`という関数はモデル構造をtensorboardに記録するための関数で、第一引数がモデル、第二引数がモデルへの入力となります。\\\n",
    "前回も説明した通りCIFAR-10は$3\\times 32\\times 32$のテンソルなのでそれと同じ形状の乱数をここでは入力しています。\\\n",
    "(もちろんデータローダーから読み出した画像データを直接入力に使用しても問題ありません。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, torch.randn(1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のセルを実行したら次のセルを実行してtensorboardを起動してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./drive/My\\ Drive/Colab\\ Notebooks/b3_proj_2023/runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linearresnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
